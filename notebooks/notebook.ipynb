{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TO DO:\n",
    "1. finish the skeleton"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix: Multilingual Type Annotated Question Pair Dataset\n",
    "\n",
    "\n",
    "This appendix reports on the collection and processing of a multilingual question pair dataset developed for research on cross-lingual semantic similarity and the representation of interrogative intent in pretrained language models. The dataset contains parallel question pairs in five languages: Afrikaans, Arabic, English, Indonesian, and Marathi. Questions were extracted from the NLLB corpus (cite) using language-specific patterns [sec X] and aligned based on their translations [sec X]. The dataset was annotated with linguistic features capturing information type (e.g., modality, quantification) and question type (e.g., polar, wh-questions) using rule-based approaches [sec X]. Preprocessing steps, including filtering, deduplication, and language balancing, were applied to ensure data quality and composition. [sec X] \n",
    "\n",
    "The result is a dataset containing ~100k question pairs adapted for investigating the interplay between language-specific features, semantic similarity, and the encoding of questions in multilingual models. The collection and processing pipeline described here is customisable to some extent and allows for varying sizes and dataset properties. However, it is important to note that this script requires local acces to NLLB alignment files and monolingual corpora, which are quite large and sometimes difficult to handle efficiently. Overall, this resource aims to support the development and evaluation of cross-lingual approaches to sentence processing tasks and to focuson the linguistic factors shaping the representation of interrogative semantics.\n",
    "\n",
    "MLE\n",
    "\n",
    "Data Collection\n",
    "3.1 Source corpora\n",
    "3.1.1 NLLB corpus\n",
    "3.1.2 Selection criteria for languages\n",
    "3.2 Question extraction\n",
    "3.2.1 QuestionDetector module\n",
    "3.2.2 Language-specific patterns and rules\n",
    "3.3 Parallel question alignment\n",
    "3.4 Data quality assurance\n",
    "\n",
    "Annotation Process\n",
    "\n",
    "4.1 Linguistic features\n",
    "4.1.1 Information type (feature1)\n",
    "4.1.2 Question type (feature2)\n",
    "4.2 Annotation guidelines and schema\n",
    "4.3 Automatic annotation\n",
    "4.3.1 Regular expressions and lexicons\n",
    "4.3.2 Validation and manual review\n",
    "4.4 Inter-annotator agreement (if applicable)\n",
    "Data Preprocessing\n",
    "\n",
    "5.1 Filtering\n",
    "5.1.1 Removal of partial and empty annotations\n",
    "5.1.2 Deduplication based on combined representation\n",
    "5.2 Balancing\n",
    "5.2.1 Downsampling of overrepresented languages\n",
    "5.2.2 Target fraction and randomization\n",
    "5.3 Data split and partitioning (if applicable)\n",
    "\n",
    "Dataset Statistics and Analysis\n",
    "6.1 Overall dataset size and composition\n",
    "6.2 Distribution of languages\n",
    "6.3 Frequency of linguistic features\n",
    "6.4 Question type and information type co-occurrences\n",
    "6.5 Cross-lingual comparisons and insights\n",
    "Data Format and Accessibility\n",
    "\n",
    "7.1 CSV structure and fields\n",
    "7.2 Accompanying JSON files\n",
    "7.3 Preprocessing scripts and reproducibility\n",
    "7.4 Licensing and data usage terms\n",
    "\n",
    "9 References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data collection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data framing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Annotation rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final filter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## Dataset statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
